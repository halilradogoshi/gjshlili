{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdb02d4d-6408-46b4-b5ac-863d9989f2d3",
   "metadata": {},
   "source": [
    "#Gjuha e shenjave shqip për instalim lokal me YOLOv8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a357736f-b0b5-4281-bcf9-fb87e574d086",
   "metadata": {},
   "source": [
    "## Importimi dhe instalimi i mvarësive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f6bba7-80e5-4c80-b2e2-754ec17c7d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Install required packages (only need to run once)\n",
    "!pip install ultralytics opencv-python matplotlib numpy scikit-learn tqdm pyyaml --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d9d1eb-adc1-4130-8ddd-1f0223466b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "import yaml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94fc7b5-2dbf-4a80-9b70-bfe87a0e9b2e",
   "metadata": {},
   "source": [
    "## Ngarkimi dhe pregatitja e të dhënave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b17ecab-25fc-4aed-bb70-479fa96747ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying train files: 100%|█████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 88.46it/s]\n",
      "Copying val files: 100%|█████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 95.12it/s]\n",
      "Copying test files: 100%|████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 83.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset structure created successfully!\n",
      "Dataset YAML file created at C:\\AI\\SingLanguageAI\\Albanian-Sign-Language-Detection\\data\\images\\albanian_signs.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Configuration\n",
    "DATASET_DIR = r\"C:\\AI\\SingLanguageAI\\Albanian-Sign-Language-Detection\\data\\images\"  # Root directory of your dataset\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO = 0.2\n",
    "TEST_RATIO = 0.1\n",
    "SEED = 42  # For reproducible splits\n",
    "\n",
    "# Create YOLOv8 dataset structure\n",
    "def create_yolov8_dataset_structure(dataset_dir, train_ratio, val_ratio, test_ratio, seed=42):\n",
    "    \"\"\"\n",
    "    Organizes the dataset into YOLOv8 expected structure:\n",
    "    - dataset/\n",
    "        - train/\n",
    "            - images/\n",
    "            - labels/\n",
    "        - val/\n",
    "            - images/\n",
    "            - labels/\n",
    "        - test/\n",
    "            - images/\n",
    "            - labels/\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(os.path.join(dataset_dir, \"train\", \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dataset_dir, \"train\", \"labels\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dataset_dir, \"val\", \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dataset_dir, \"val\", \"labels\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dataset_dir, \"test\", \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dataset_dir, \"test\", \"labels\"), exist_ok=True)\n",
    "    \n",
    "    # Get list of all image files (assuming .jpg format)\n",
    "    image_files = [f for f in os.listdir(dataset_dir) if f.endswith('.jpg')]\n",
    "    \n",
    "    # Split into train, val, test\n",
    "    train_files, temp_files = train_test_split(image_files, train_size=train_ratio, random_state=seed)\n",
    "    val_files, test_files = train_test_split(temp_files, test_size=test_ratio/(val_ratio+test_ratio), random_state=seed)\n",
    "    \n",
    "    # Helper function to copy files\n",
    "    def copy_files(files, split):\n",
    "        for file in tqdm(files, desc=f\"Copying {split} files\"):\n",
    "            # Copy image\n",
    "            src_img = os.path.join(dataset_dir, file)\n",
    "            dst_img = os.path.join(dataset_dir, split, \"images\", file)\n",
    "            shutil.copy(src_img, dst_img)\n",
    "            \n",
    "            # Copy corresponding label file\n",
    "            label_file = os.path.splitext(file)[0] + '.txt'\n",
    "            src_label = os.path.join(dataset_dir, label_file)\n",
    "            dst_label = os.path.join(dataset_dir, split, \"labels\", label_file)\n",
    "            if os.path.exists(src_label):\n",
    "                shutil.copy(src_label, dst_label)\n",
    "    \n",
    "    # Copy files to respective directories\n",
    "    copy_files(train_files, \"train\")\n",
    "    copy_files(val_files, \"val\")\n",
    "    copy_files(test_files, \"test\")\n",
    "    \n",
    "    print(\"Dataset structure created successfully!\")\n",
    "\n",
    "# Create the dataset structure\n",
    "create_yolov8_dataset_structure(DATASET_DIR, TRAIN_RATIO, VAL_RATIO, TEST_RATIO, SEED)\n",
    "\n",
    "# Create dataset YAML file\n",
    "data_yaml = {\n",
    "    'train': os.path.join(DATASET_DIR, 'train', 'images'),\n",
    "    'val': os.path.join(DATASET_DIR, 'val', 'images'),\n",
    "    'test': os.path.join(DATASET_DIR, 'test', 'images'),\n",
    "    'nc': 6,  # Number of classes (Albanian alphabet has 36 letters)\n",
    "    'names': [\n",
    "        'C', 'E', 'G', 'L', 'O', 'V'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Save the YAML file\n",
    "yaml_path = os.path.join(DATASET_DIR, 'albanian_signs.yaml')\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(data_yaml, f)\n",
    "\n",
    "print(f\"Dataset YAML file created at {yaml_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654fd698-5c2e-418d-86a5-92fcb88cd89b",
   "metadata": {},
   "source": [
    "Ngarkimi dhe përshtatja e modelit Yolo V8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b40b2e07-74a3-4b38-87c1-e26b2543800b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n summary: 129 layers, 3,157,200 parameters, 0 gradients, 8.9 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(129, 3157200, 0, 8.8575488)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# Load a pretrained YOLOv8n model (you can choose different sizes: n, s, m, l, x)\n",
    "model = YOLO('yolov8n.pt')  # Load a pretrained model (recommended for training)\n",
    "\n",
    "# Display model architecture (optional)\n",
    "model.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ea1ccc-2c48-44ea-a33d-72536d76c49b",
   "metadata": {},
   "source": [
    "## Trajnimi i modelit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fd2bc79-8377-4161-afe7-b061762a2917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.115  Python-3.10.16 torch-2.7.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=C:\\AI\\SingLanguageAI\\Albanian-Sign-Language-Detection\\data\\images\\albanian_signs.yaml, epochs=50, time=None, patience=10, batch=8, imgsz=(1024, 768), save=True, save_period=5, cache=False, device=cpu, workers=8, project=albanian_signs_detection, name=train14, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=True, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=albanian_signs_detection\\train14\n",
      "Overriding model.yaml nc=80 with nc=6\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752482  ultralytics.nn.modules.head.Detect           [6, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,012,018 parameters, 3,012,002 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "WARNING updating to 'imgsz=1024'. 'train' and 'val' imgsz must be an integer, while 'predict' and 'export' imgsz may be a [h, w] list or an integer, i.e. 'yolo export imgsz=640,480' or 'yolo export imgsz=640'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.30.1 ms, read: 382.275.5 MB/s, size: 543.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\AI\\SingLanguageAI\\Albanian-Sign-Language-Detection\\data\\images\\train\\labels... 10 images, 0 backgrou\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\AI\\SingLanguageAI\\Albanian-Sign-Language-Detection\\data\\images\\train\\labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.30.0 ms, read: 446.788.9 MB/s, size: 619.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\hara11\\AppData\\Local\\anaconda3\\envs\\gjsh_lili\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\AI\\SingLanguageAI\\Albanian-Sign-Language-Detection\\data\\images\\val\\labels... 3 images, 0 backgrounds, \u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\AI\\SingLanguageAI\\Albanian-Sign-Language-Detection\\data\\images\\val\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\hara11\\AppData\\Local\\anaconda3\\envs\\gjsh_lili\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to albanian_signs_detection\\train14\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 1024 train, 1024 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1malbanian_signs_detection\\train14\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G      2.744      6.595      3.624          4       1024: 100%|██████████| 2/2 [00:14<00:00,  7.44\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3    0.00842          1      0.198     0.0687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50         0G      2.472      5.725       3.43          4       1024: 100%|██████████| 2/2 [00:13<00:00,  6.82\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3    0.00887          1      0.213      0.104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50         0G      2.565      6.274      3.487          3       1024: 100%|██████████| 2/2 [00:13<00:00,  6.97\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3    0.00917          1      0.205     0.0863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50         0G      1.308      4.204      2.025          8       1024: 100%|██████████| 2/2 [00:13<00:00,  6.99\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3     0.0103          1      0.332     0.0977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50         0G      1.729      4.982      2.729          4       1024: 100%|██████████| 2/2 [00:13<00:00,  6.92\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3     0.0104          1      0.332     0.0931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50         0G      1.377      4.237      2.365          7       1024: 100%|██████████| 2/2 [00:13<00:00,  6.86\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3     0.0118          1      0.442      0.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50         0G      1.282      4.561      2.155          8       1024: 100%|██████████| 2/2 [00:13<00:00,  6.86\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3     0.0116          1      0.398       0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50         0G      1.421      4.303       2.26          5       1024: 100%|██████████| 2/2 [00:13<00:00,  6.90\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3     0.0111          1      0.219     0.0923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50         0G      1.379      4.009      2.227          6       1024: 100%|██████████| 2/2 [00:13<00:00,  6.84\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3     0.0114          1      0.359      0.148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50         0G      1.582      3.985      2.446          5       1024: 100%|██████████| 2/2 [00:13<00:00,  6.99\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3     0.0113          1       0.58      0.292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50         0G      1.599      4.368      2.656          4       1024: 100%|██████████| 2/2 [00:13<00:00,  6.86\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3      0.012          1      0.774      0.288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50         0G      1.263      3.903      2.144          5       1024: 100%|██████████| 2/2 [00:13<00:00,  6.80\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3      0.012          1      0.774      0.288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50         0G      1.173      3.897      2.136          5       1024: 100%|██████████| 2/2 [00:13<00:00,  6.96\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3     0.0123          1      0.774      0.322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50         0G      1.217      4.581      2.483          2       1024: 100%|██████████| 2/2 [00:13<00:00,  6.93\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3     0.0118          1      0.525      0.213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50         0G      1.104      3.305      1.844          7       1024: 100%|██████████| 2/2 [00:13<00:00,  6.87\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3     0.0118          1      0.525      0.213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50         0G      1.133      3.394      1.777          8       1024: 100%|██████████| 2/2 [00:13<00:00,  6.67\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3     0.0127          1      0.525      0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50         0G      1.046      3.398      1.781          6       1024: 100%|██████████| 2/2 [00:13<00:00,  6.71\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3     0.0146          1      0.774      0.451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50         0G      1.263      3.709      1.994          6       1024: 100%|██████████| 2/2 [00:13<00:00,  6.86\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3     0.0146          1      0.774      0.451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50         0G      1.184      4.514      2.105          2       1024: 100%|██████████| 2/2 [00:13<00:00,  6.85\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3     0.0169          1      0.398      0.242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50         0G      1.002      3.188      1.689          6       1024: 100%|██████████| 2/2 [00:13<00:00,  6.87\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3     0.0169          1      0.398      0.242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50         0G      1.066      3.232      1.738          7       1024: 100%|██████████| 2/2 [00:13<00:00,  6.90\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3     0.0173          1      0.442      0.298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50         0G      1.186      3.821      1.866          3       1024: 100%|██████████| 2/2 [00:13<00:00,  6.76\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3     0.0173          1      0.442      0.298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50         0G      1.033      3.226      1.706          5       1024: 100%|██████████| 2/2 [00:14<00:00,  7.19\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3     0.0146          1      0.608      0.352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50         0G      1.128      3.179      1.925          6       1024: 100%|██████████| 2/2 [00:14<00:00,  7.06\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3     0.0146          1      0.608      0.352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50         0G       1.08      3.126      1.632          7       1024: 100%|██████████| 2/2 [00:13<00:00,  6.99\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3     0.0134          1      0.663      0.406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50         0G      1.059      3.277      1.879          5       1024: 100%|██████████| 2/2 [00:13<00:00,  6.83\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3     0.0134          1      0.663      0.406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50         0G     0.9558      2.709      1.774          6       1024: 100%|██████████| 2/2 [00:13<00:00,  6.84\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3     0.0134          1      0.663      0.406\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 17, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "27 epochs completed in 0.127 hours.\n",
      "Optimizer stripped from albanian_signs_detection\\train14\\weights\\last.pt, 6.3MB\n",
      "Optimizer stripped from albanian_signs_detection\\train14\\weights\\best.pt, 6.3MB\n",
      "\n",
      "Validating albanian_signs_detection\\train14\\weights\\best.pt...\n",
      "Ultralytics 8.3.115  Python-3.10.16 torch-2.7.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "Model summary (fused): 72 layers, 3,006,818 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          3          3     0.0165          1       0.58      0.522\n",
      "                     C          1          1     0.0159          1      0.249      0.224\n",
      "                     E          1          1     0.0143          1      0.497      0.448\n",
      "                     G          1          1     0.0192          1      0.995      0.895\n",
      "Speed: 8.6ms preprocess, 622.6ms inference, 0.0ms loss, 159.5ms postprocess per image\n",
      "Results saved to \u001b[1malbanian_signs_detection\\train14\u001b[0m\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "import torch  # Add this import\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# %%\n",
    "# Training configuration\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 0.01\n",
    "IMG_SIZE = (1024)\n",
    "PATIENCE = 10  # Early stopping patience\n",
    "DEVICE = '0' if torch.cuda.is_available() else 'cpu'  # Use GPU if available\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data=yaml_path,\n",
    "    epochs=EPOCHS,\n",
    "    batch=BATCH_SIZE,\n",
    "    lr0=LEARNING_RATE,\n",
    "    imgsz=IMG_SIZE,\n",
    "    patience=PATIENCE,\n",
    "    device=DEVICE,\n",
    "    project='albanian_signs_detection',\n",
    "    name='train1',\n",
    "    save=True,\n",
    "    save_period=5,  # Save checkpoint every 5 epochs\n",
    "    visualize=True,  # Visualize training progress\n",
    "    augment=True,  # Apply mosaic augmentation\n",
    "    cache=False  # Cache images for faster training (requires more RAM)\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a4e606-ce6a-4383-b2e4-463866c367fc",
   "metadata": {},
   "source": [
    "## Vlerësimi i performancës "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93aa1294-a1ab-4588-9fb7-f41214840397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING updating to 'imgsz=1024'. 'train' and 'val' imgsz must be an integer, while 'predict' and 'export' imgsz may be a [h, w] list or an integer, i.e. 'yolo export imgsz=640,480' or 'yolo export imgsz=640'\n",
      "Ultralytics 8.3.115  Python-3.10.16 torch-2.7.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "Model summary (fused): 72 layers, 3,012,668 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.30.0 ms, read: 292.62.6 MB/s, size: 502.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\AI\\SingLanguageAI\\Albanian-Sign-Language-Detection\\data\\images\\test\\labels... 2 images, 0 backgrounds,\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\AI\\SingLanguageAI\\Albanian-Sign-Language-Detection\\data\\images\\test\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\hara11\\AppData\\Local\\anaconda3\\envs\\gjsh_lili\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          2          2          0          0          0          0\n",
      "                     B          1          1          0          0          0          0\n",
      "                     C          1          1          0          0          0          0\n",
      "Speed: 9.9ms preprocess, 285.5ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val4\u001b[0m\n",
      "\n",
      "Evaluation Metrics:\n",
      "mAP@0.5: 0.0000\n",
      "mAP@0.5:0.95: 0.0000\n",
      "Mean Precision: 0.0000\n",
      "Mean Recall: 0.0000\n",
      "\n",
      "image 1/1 C:\\AI\\SingLanguageAI\\Albanian-Sign-Language-Detection\\data\\images\\test\\images\\cvimg_14.jpg: 640x480 (no detections), 187.2ms\n",
      "Speed: 8.7ms preprocess, 187.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\AI\\SingLanguageAI\\Albanian-Sign-Language-Detection\\data\\images\\test\\images\\cvimg_6.jpg: 640x480 (no detections), 125.8ms\n",
      "Speed: 9.0ms preprocess, 125.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the best model from training\n",
    "best_model_path = os.path.join('albanian_signs_detection', 'train1', 'weights', 'best.pt')\n",
    "best_model = YOLO(best_model_path)\n",
    "\n",
    "# Evaluate model performance on the test set\n",
    "metrics = best_model.val(\n",
    "    data=yaml_path,\n",
    "    split='test',\n",
    "    batch=BATCH_SIZE,\n",
    "    imgsz=IMG_SIZE,\n",
    "    conf=0.25,  # Confidence threshold\n",
    "    iou=0.45,  # IoU threshold\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "# Print evaluation metrics - UPDATED FOR YOLOv8.3+\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(f\"mAP@0.5: {metrics.box.map50:.4f}\")  # mAP@0.5\n",
    "print(f\"mAP@0.5:0.95: {metrics.box.map:.4f}\")  # mAP@0.5:0.95\n",
    "print(f\"Mean Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"Mean Recall: {metrics.box.mr:.4f}\")\n",
    "\n",
    "# Plot some predictions on test images\n",
    "test_images_dir = os.path.join(DATASET_DIR, 'test', 'images')\n",
    "test_images = [os.path.join(test_images_dir, f) for f in os.listdir(test_images_dir) if f.endswith('.jpg')][:5]  # First 5 images\n",
    "\n",
    "for img_path in test_images:\n",
    "    results = best_model(img_path)\n",
    "    for r in results:\n",
    "        im_array = r.plot()  # Plot a BGR numpy array of predictions\n",
    "        im = cv2.cvtColor(im_array, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "        \n",
    "        # Display in notebook\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(im)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888b0b39-dc2a-4d71-9f64-0b114262e278",
   "metadata": {},
   "source": [
    "## Testimi me kamerë"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d75a2327-c93d-4dc3-9e35-0dbfac326ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting webcam inference... Press 'q' to quit.\n",
      "\n",
      "0: 480x640 (no detections), 196.2ms\n",
      "Speed: 5.3ms preprocess, 196.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 135.9ms\n",
      "Speed: 5.3ms preprocess, 135.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 127.4ms\n",
      "Speed: 4.3ms preprocess, 127.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 126.9ms\n",
      "Speed: 3.9ms preprocess, 126.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 127.2ms\n",
      "Speed: 3.9ms preprocess, 127.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 125.4ms\n",
      "Speed: 4.4ms preprocess, 125.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 131.2ms\n",
      "Speed: 3.8ms preprocess, 131.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 134.6ms\n",
      "Speed: 4.8ms preprocess, 134.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 135.5ms\n",
      "Speed: 4.4ms preprocess, 135.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 127.9ms\n",
      "Speed: 3.1ms preprocess, 127.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 131.2ms\n",
      "Speed: 4.1ms preprocess, 131.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 126.8ms\n",
      "Speed: 3.4ms preprocess, 126.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 134.6ms\n",
      "Speed: 4.4ms preprocess, 134.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 63.0ms\n",
      "Speed: 3.1ms preprocess, 63.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.1ms\n",
      "Speed: 1.8ms preprocess, 55.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.3ms\n",
      "Speed: 1.6ms preprocess, 55.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.3ms\n",
      "Speed: 1.5ms preprocess, 52.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 56.7ms\n",
      "Speed: 1.3ms preprocess, 56.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.5ms\n",
      "Speed: 1.7ms preprocess, 54.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.7ms\n",
      "Speed: 1.2ms preprocess, 54.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.3ms\n",
      "Speed: 1.5ms preprocess, 51.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.5ms\n",
      "Speed: 1.5ms preprocess, 54.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.6ms\n",
      "Speed: 2.3ms preprocess, 52.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.8ms\n",
      "Speed: 1.6ms preprocess, 55.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.2ms\n",
      "Speed: 1.5ms preprocess, 55.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.3ms\n",
      "Speed: 1.3ms preprocess, 53.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.9ms\n",
      "Speed: 1.4ms preprocess, 53.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.9ms\n",
      "Speed: 1.4ms preprocess, 51.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.8ms\n",
      "Speed: 1.7ms preprocess, 55.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 56.0ms\n",
      "Speed: 1.8ms preprocess, 56.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.1ms\n",
      "Speed: 2.8ms preprocess, 52.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.2ms\n",
      "Speed: 1.3ms preprocess, 52.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 50.2ms\n",
      "Speed: 1.3ms preprocess, 50.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 56.0ms\n",
      "Speed: 1.2ms preprocess, 56.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.2ms\n",
      "Speed: 1.5ms preprocess, 53.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.2ms\n",
      "Speed: 1.3ms preprocess, 52.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 56.1ms\n",
      "Speed: 1.5ms preprocess, 56.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.5ms\n",
      "Speed: 1.5ms preprocess, 53.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.4ms\n",
      "Speed: 1.3ms preprocess, 53.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.0ms\n",
      "Speed: 1.8ms preprocess, 55.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.2ms\n",
      "Speed: 1.7ms preprocess, 53.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.2ms\n",
      "Speed: 1.6ms preprocess, 54.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 87.7ms\n",
      "Speed: 2.4ms preprocess, 87.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.3ms\n",
      "Speed: 1.8ms preprocess, 54.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.3ms\n",
      "Speed: 1.6ms preprocess, 54.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 57.4ms\n",
      "Speed: 1.7ms preprocess, 57.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.6ms\n",
      "Speed: 1.4ms preprocess, 51.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 56.3ms\n",
      "Speed: 1.6ms preprocess, 56.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.3ms\n",
      "Speed: 1.2ms preprocess, 53.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 56.3ms\n",
      "Speed: 1.5ms preprocess, 56.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 50.2ms\n",
      "Speed: 1.4ms preprocess, 50.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 56.9ms\n",
      "Speed: 1.6ms preprocess, 56.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.3ms\n",
      "Speed: 1.2ms preprocess, 52.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.5ms\n",
      "Speed: 1.3ms preprocess, 51.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 57.7ms\n",
      "Speed: 1.3ms preprocess, 57.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 58.8ms\n",
      "Speed: 1.6ms preprocess, 58.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 57.4ms\n",
      "Speed: 2.1ms preprocess, 57.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.9ms\n",
      "Speed: 1.4ms preprocess, 51.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.2ms\n",
      "Speed: 1.6ms preprocess, 52.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.1ms\n",
      "Speed: 1.3ms preprocess, 52.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 58.2ms\n",
      "Speed: 1.3ms preprocess, 58.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.6ms\n",
      "Speed: 1.5ms preprocess, 52.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 57.1ms\n",
      "Speed: 1.6ms preprocess, 57.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 59.3ms\n",
      "Speed: 1.9ms preprocess, 59.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 60.6ms\n",
      "Speed: 1.4ms preprocess, 60.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 57.1ms\n",
      "Speed: 1.4ms preprocess, 57.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 58.8ms\n",
      "Speed: 1.4ms preprocess, 58.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.5ms\n",
      "Speed: 2.2ms preprocess, 51.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.1ms\n",
      "Speed: 1.5ms preprocess, 53.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.5ms\n",
      "Speed: 1.3ms preprocess, 53.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.7ms\n",
      "Speed: 1.5ms preprocess, 51.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 56.9ms\n",
      "Speed: 1.4ms preprocess, 56.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.9ms\n",
      "Speed: 1.5ms preprocess, 55.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 58.3ms\n",
      "Speed: 1.7ms preprocess, 58.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.3ms\n",
      "Speed: 1.3ms preprocess, 53.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.9ms\n",
      "Speed: 1.6ms preprocess, 55.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.2ms\n",
      "Speed: 1.7ms preprocess, 53.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.0ms\n",
      "Speed: 2.1ms preprocess, 54.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 50.4ms\n",
      "Speed: 2.2ms preprocess, 50.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 49.7ms\n",
      "Speed: 1.6ms preprocess, 49.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.7ms\n",
      "Speed: 1.5ms preprocess, 52.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.2ms\n",
      "Speed: 1.3ms preprocess, 51.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.1ms\n",
      "Speed: 1.3ms preprocess, 53.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 58.3ms\n",
      "Speed: 1.3ms preprocess, 58.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.6ms\n",
      "Speed: 2.4ms preprocess, 53.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.6ms\n",
      "Speed: 1.4ms preprocess, 52.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.3ms\n",
      "Speed: 1.7ms preprocess, 54.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 49.2ms\n",
      "Speed: 1.8ms preprocess, 49.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.4ms\n",
      "Speed: 1.4ms preprocess, 52.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.0ms\n",
      "Speed: 1.5ms preprocess, 54.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 50.9ms\n",
      "Speed: 1.5ms preprocess, 50.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.3ms\n",
      "Speed: 1.3ms preprocess, 54.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.8ms\n",
      "Speed: 1.6ms preprocess, 51.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 50.8ms\n",
      "Speed: 1.4ms preprocess, 50.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.5ms\n",
      "Speed: 1.8ms preprocess, 55.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.9ms\n",
      "Speed: 2.7ms preprocess, 54.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.9ms\n",
      "Speed: 1.4ms preprocess, 54.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.4ms\n",
      "Speed: 1.5ms preprocess, 52.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.1ms\n",
      "Speed: 1.8ms preprocess, 55.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.9ms\n",
      "Speed: 1.6ms preprocess, 52.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.8ms\n",
      "Speed: 1.3ms preprocess, 53.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 57.6ms\n",
      "Speed: 1.8ms preprocess, 57.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 50.7ms\n",
      "Speed: 1.8ms preprocess, 50.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.6ms\n",
      "Speed: 1.6ms preprocess, 51.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 59.7ms\n",
      "Speed: 1.5ms preprocess, 59.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.6ms\n",
      "Speed: 1.4ms preprocess, 51.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 50.1ms\n",
      "Speed: 1.8ms preprocess, 50.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.4ms\n",
      "Speed: 1.3ms preprocess, 52.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.8ms\n",
      "Speed: 1.5ms preprocess, 51.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.9ms\n",
      "Speed: 1.4ms preprocess, 53.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.1ms\n",
      "Speed: 1.9ms preprocess, 51.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 50.1ms\n",
      "Speed: 1.4ms preprocess, 50.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.3ms\n",
      "Speed: 1.9ms preprocess, 51.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 49.6ms\n",
      "Speed: 1.4ms preprocess, 49.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.9ms\n",
      "Speed: 1.5ms preprocess, 53.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.6ms\n",
      "Speed: 1.6ms preprocess, 54.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 76.6ms\n",
      "Speed: 2.4ms preprocess, 76.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 56.4ms\n",
      "Speed: 2.1ms preprocess, 56.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 58.8ms\n",
      "Speed: 1.9ms preprocess, 58.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 56.3ms\n",
      "Speed: 1.7ms preprocess, 56.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.9ms\n",
      "Speed: 1.4ms preprocess, 53.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.3ms\n",
      "Speed: 1.6ms preprocess, 55.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.9ms\n",
      "Speed: 1.4ms preprocess, 54.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.5ms\n",
      "Speed: 1.4ms preprocess, 52.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.0ms\n",
      "Speed: 1.5ms preprocess, 54.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.0ms\n",
      "Speed: 1.7ms preprocess, 55.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 50.0ms\n",
      "Speed: 1.3ms preprocess, 50.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.1ms\n",
      "Speed: 1.6ms preprocess, 54.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.5ms\n",
      "Speed: 2.1ms preprocess, 52.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 50.1ms\n",
      "Speed: 1.4ms preprocess, 50.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.9ms\n",
      "Speed: 1.5ms preprocess, 54.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.5ms\n",
      "Speed: 1.4ms preprocess, 54.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.5ms\n",
      "Speed: 1.7ms preprocess, 55.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.0ms\n",
      "Speed: 1.3ms preprocess, 52.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.1ms\n",
      "Speed: 1.9ms preprocess, 53.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.9ms\n",
      "Speed: 1.4ms preprocess, 53.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.9ms\n",
      "Speed: 1.6ms preprocess, 54.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.4ms\n",
      "Speed: 2.0ms preprocess, 51.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 50.2ms\n",
      "Speed: 1.3ms preprocess, 50.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 49.7ms\n",
      "Speed: 1.7ms preprocess, 49.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.7ms\n",
      "Speed: 1.5ms preprocess, 52.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.6ms\n",
      "Speed: 1.5ms preprocess, 51.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 50.1ms\n",
      "Speed: 1.8ms preprocess, 50.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.0ms\n",
      "Speed: 2.0ms preprocess, 53.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.4ms\n",
      "Speed: 1.8ms preprocess, 52.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 56.0ms\n",
      "Speed: 2.2ms preprocess, 56.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.3ms\n",
      "Speed: 1.5ms preprocess, 53.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.6ms\n",
      "Speed: 1.6ms preprocess, 52.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 56.0ms\n",
      "Speed: 1.5ms preprocess, 56.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.0ms\n",
      "Speed: 1.9ms preprocess, 51.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.0ms\n",
      "Speed: 1.3ms preprocess, 52.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.4ms\n",
      "Speed: 1.7ms preprocess, 51.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.9ms\n",
      "Speed: 1.7ms preprocess, 54.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.6ms\n",
      "Speed: 1.8ms preprocess, 52.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.6ms\n",
      "Speed: 1.5ms preprocess, 55.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 56.9ms\n",
      "Speed: 2.2ms preprocess, 56.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.0ms\n",
      "Speed: 1.6ms preprocess, 54.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.3ms\n",
      "Speed: 1.7ms preprocess, 52.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 56.1ms\n",
      "Speed: 1.6ms preprocess, 56.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.3ms\n",
      "Speed: 1.2ms preprocess, 54.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.0ms\n",
      "Speed: 1.4ms preprocess, 52.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.8ms\n",
      "Speed: 1.8ms preprocess, 52.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.6ms\n",
      "Speed: 1.7ms preprocess, 53.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 56.0ms\n",
      "Speed: 1.6ms preprocess, 56.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.6ms\n",
      "Speed: 1.7ms preprocess, 55.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 93.4ms\n",
      "Speed: 2.0ms preprocess, 93.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 57.4ms\n",
      "Speed: 1.7ms preprocess, 57.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.9ms\n",
      "Speed: 1.5ms preprocess, 53.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.7ms\n",
      "Speed: 1.4ms preprocess, 52.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.4ms\n",
      "Speed: 1.2ms preprocess, 52.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.3ms\n",
      "Speed: 2.3ms preprocess, 53.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.1ms\n",
      "Speed: 1.4ms preprocess, 54.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.7ms\n",
      "Speed: 1.5ms preprocess, 53.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.3ms\n",
      "Speed: 2.0ms preprocess, 52.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.0ms\n",
      "Speed: 1.5ms preprocess, 52.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.2ms\n",
      "Speed: 2.5ms preprocess, 52.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.5ms\n",
      "Speed: 1.6ms preprocess, 53.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 62.2ms\n",
      "Speed: 1.5ms preprocess, 62.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.1ms\n",
      "Speed: 1.3ms preprocess, 53.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.6ms\n",
      "Speed: 2.6ms preprocess, 52.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.0ms\n",
      "Speed: 1.3ms preprocess, 53.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.1ms\n",
      "Speed: 1.6ms preprocess, 53.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.8ms\n",
      "Speed: 1.6ms preprocess, 51.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.2ms\n",
      "Speed: 1.7ms preprocess, 53.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.9ms\n",
      "Speed: 1.3ms preprocess, 53.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.1ms\n",
      "Speed: 1.4ms preprocess, 55.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.4ms\n",
      "Speed: 1.4ms preprocess, 52.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.2ms\n",
      "Speed: 1.5ms preprocess, 53.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.5ms\n",
      "Speed: 1.7ms preprocess, 55.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 49.5ms\n",
      "Speed: 1.8ms preprocess, 49.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 50.9ms\n",
      "Speed: 1.6ms preprocess, 50.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 57.7ms\n",
      "Speed: 1.6ms preprocess, 57.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 50.7ms\n",
      "Speed: 2.2ms preprocess, 50.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.6ms\n",
      "Speed: 1.3ms preprocess, 52.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 56.4ms\n",
      "Speed: 1.7ms preprocess, 56.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.1ms\n",
      "Speed: 1.6ms preprocess, 55.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.7ms\n",
      "Speed: 1.6ms preprocess, 51.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.7ms\n",
      "Speed: 1.4ms preprocess, 54.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.5ms\n",
      "Speed: 1.6ms preprocess, 55.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.9ms\n",
      "Speed: 1.5ms preprocess, 53.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.4ms\n",
      "Speed: 1.5ms preprocess, 55.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.2ms\n",
      "Speed: 2.0ms preprocess, 54.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.0ms\n",
      "Speed: 1.7ms preprocess, 54.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.9ms\n",
      "Speed: 1.7ms preprocess, 54.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.2ms\n",
      "Speed: 1.5ms preprocess, 53.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 59.0ms\n",
      "Speed: 1.4ms preprocess, 59.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 86.3ms\n",
      "Speed: 1.9ms preprocess, 86.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.5ms\n",
      "Speed: 1.8ms preprocess, 55.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.6ms\n",
      "Speed: 1.5ms preprocess, 51.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.9ms\n",
      "Speed: 1.7ms preprocess, 55.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.5ms\n",
      "Speed: 1.7ms preprocess, 54.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 49.6ms\n",
      "Speed: 1.3ms preprocess, 49.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 49.1ms\n",
      "Speed: 1.7ms preprocess, 49.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.1ms\n",
      "Speed: 2.0ms preprocess, 52.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 58.7ms\n",
      "Speed: 1.7ms preprocess, 58.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.2ms\n",
      "Speed: 1.4ms preprocess, 55.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.2ms\n",
      "Speed: 1.6ms preprocess, 54.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.6ms\n",
      "Speed: 1.2ms preprocess, 51.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 59.0ms\n",
      "Speed: 2.4ms preprocess, 59.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.3ms\n",
      "Speed: 1.6ms preprocess, 52.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.6ms\n",
      "Speed: 1.5ms preprocess, 53.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 57.2ms\n",
      "Speed: 1.2ms preprocess, 57.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.2ms\n",
      "Speed: 2.4ms preprocess, 54.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.5ms\n",
      "Speed: 1.8ms preprocess, 55.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.5ms\n",
      "Speed: 1.5ms preprocess, 52.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.2ms\n",
      "Speed: 1.5ms preprocess, 55.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.6ms\n",
      "Speed: 1.6ms preprocess, 55.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 49.8ms\n",
      "Speed: 1.4ms preprocess, 49.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.5ms\n",
      "Speed: 1.8ms preprocess, 51.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.8ms\n",
      "Speed: 1.6ms preprocess, 52.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 49.0ms\n",
      "Speed: 1.8ms preprocess, 49.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 50.5ms\n",
      "Speed: 1.6ms preprocess, 50.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.5ms\n",
      "Speed: 1.7ms preprocess, 53.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 48.9ms\n",
      "Speed: 1.4ms preprocess, 48.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.0ms\n",
      "Speed: 1.7ms preprocess, 55.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.6ms\n",
      "Speed: 1.3ms preprocess, 52.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.5ms\n",
      "Speed: 1.7ms preprocess, 51.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.6ms\n",
      "Speed: 1.9ms preprocess, 51.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.4ms\n",
      "Speed: 1.6ms preprocess, 51.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 50.2ms\n",
      "Speed: 1.4ms preprocess, 50.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.0ms\n",
      "Speed: 1.8ms preprocess, 52.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.6ms\n",
      "Speed: 1.4ms preprocess, 52.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.7ms\n",
      "Speed: 2.1ms preprocess, 51.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.3ms\n",
      "Speed: 2.0ms preprocess, 53.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.5ms\n",
      "Speed: 1.9ms preprocess, 55.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 58.0ms\n",
      "Speed: 2.0ms preprocess, 58.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 59.4ms\n",
      "Speed: 2.2ms preprocess, 59.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 61.2ms\n",
      "Speed: 1.7ms preprocess, 61.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 62.2ms\n",
      "Speed: 1.5ms preprocess, 62.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 60.6ms\n",
      "Speed: 1.8ms preprocess, 60.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 60.8ms\n",
      "Speed: 2.3ms preprocess, 60.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 61.4ms\n",
      "Speed: 1.7ms preprocess, 61.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.1ms\n",
      "Speed: 1.7ms preprocess, 54.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 58.4ms\n",
      "Speed: 1.5ms preprocess, 58.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 57.7ms\n",
      "Speed: 1.8ms preprocess, 57.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.5ms\n",
      "Speed: 2.2ms preprocess, 51.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 58.6ms\n",
      "Speed: 2.2ms preprocess, 58.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 58.7ms\n",
      "Speed: 2.4ms preprocess, 58.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 92.7ms\n",
      "Speed: 2.2ms preprocess, 92.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 59.1ms\n",
      "Speed: 1.5ms preprocess, 59.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 103.3ms\n",
      "Speed: 2.0ms preprocess, 103.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 60.2ms\n",
      "Speed: 1.8ms preprocess, 60.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.8ms\n",
      "Speed: 2.0ms preprocess, 54.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.1ms\n",
      "Speed: 1.6ms preprocess, 55.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.5ms\n",
      "Speed: 1.3ms preprocess, 53.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.6ms\n",
      "Speed: 1.5ms preprocess, 54.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 59.0ms\n",
      "Speed: 1.3ms preprocess, 59.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.4ms\n",
      "Speed: 2.0ms preprocess, 54.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.9ms\n",
      "Speed: 1.4ms preprocess, 52.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 56.1ms\n",
      "Speed: 1.7ms preprocess, 56.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 50.5ms\n",
      "Speed: 2.3ms preprocess, 50.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 55.5ms\n",
      "Speed: 1.9ms preprocess, 55.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.0ms\n",
      "Speed: 1.4ms preprocess, 54.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 57.5ms\n",
      "Speed: 1.7ms preprocess, 57.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 57.4ms\n",
      "Speed: 1.1ms preprocess, 57.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.7ms\n",
      "Speed: 1.3ms preprocess, 53.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.4ms\n",
      "Speed: 1.7ms preprocess, 52.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 62.3ms\n",
      "Speed: 1.9ms preprocess, 62.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.7ms\n",
      "Speed: 1.9ms preprocess, 53.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 54.8ms\n",
      "Speed: 1.9ms preprocess, 54.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 49.7ms\n",
      "Speed: 1.4ms preprocess, 49.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.5ms\n",
      "Speed: 1.2ms preprocess, 52.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 52.0ms\n",
      "Speed: 1.9ms preprocess, 52.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.6ms\n",
      "Speed: 2.6ms preprocess, 51.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 57.5ms\n",
      "Speed: 2.5ms preprocess, 57.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 56.0ms\n",
      "Speed: 1.6ms preprocess, 56.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 53.3ms\n",
      "Speed: 2.0ms preprocess, 53.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 51.9ms\n",
      "Speed: 1.5ms preprocess, 51.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "def run_webcam_inference(model, conf_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Run real-time inference using webcam\n",
    "    Args:\n",
    "        model: YOLOv8 model\n",
    "        conf_threshold: Confidence threshold for detection\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(0)  # 0 for default webcam\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "    \n",
    "    print(\"Starting webcam inference... Press 'q' to quit.\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Could not read frame.\")\n",
    "            break\n",
    "        \n",
    "        # Run inference\n",
    "        results = model(frame, conf=conf_threshold)\n",
    "        \n",
    "        # Visualize results\n",
    "        annotated_frame = results[0].plot()\n",
    "        \n",
    "        # Display the annotated frame\n",
    "        cv2.imshow(\"Albanian Sign Detection\", annotated_frame)\n",
    "        \n",
    "        # Break the loop on 'q' key\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run webcam inference with the best model\n",
    "run_webcam_inference(best_model, conf_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1037198-3857-415b-93b0-7ac05e1d894b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
